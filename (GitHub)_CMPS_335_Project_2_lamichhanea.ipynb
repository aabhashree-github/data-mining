{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "(GitHub) CMPS 335 Project 2 lamichhanea.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aabhashree-github/python-visualization/blob/main/(GitHub)_CMPS_335_Project_2_lamichhanea.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljOJIcuCB-t7"
      },
      "source": [
        "# Project 2\n",
        "\n",
        "This project is about using cross-validation to explore hyperparameter options for two different types of models. We are using a random forest model and a k-nearest neighbors model.\n",
        "\n",
        "We are using another dataset with a long history in machine learning, a dataset from the Univerisity of Wisconsin on breast cancer.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NacG5jMbMssN",
        "outputId": "54885e84-7225-4881-d160-14a54a4afeaf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekp5Jw8enH5s"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5srQlLDZjy3m",
        "outputId": "fda04295-5b10-4f56-94d1-0eac6969e55c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        }
      },
      "source": [
        "# Read in the dataset and specify the id column to be row indices\n",
        "bcwd = pd.read_csv('/content/drive/My Drive/Hollins Data Science/Datasets/breast_cancer_wisconsin_diagnostic.csv', index_col='id')\n",
        "# Recode the classes with numbers\n",
        "bcwd['diagnosis'].replace('M',1, inplace=True)\n",
        "bcwd['diagnosis'].replace('B',0, inplace=True)\n",
        "bcwd.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>diagnosis</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>radius_se</th>\n",
              "      <th>texture_se</th>\n",
              "      <th>perimeter_se</th>\n",
              "      <th>area_se</th>\n",
              "      <th>smoothness_se</th>\n",
              "      <th>compactness_se</th>\n",
              "      <th>concavity_se</th>\n",
              "      <th>concave points_se</th>\n",
              "      <th>symmetry_se</th>\n",
              "      <th>fractal_dimension_se</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>842302</th>\n",
              "      <td>1</td>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1.0950</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8.589</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.01587</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>842517</th>\n",
              "      <td>1</td>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3.398</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84300903</th>\n",
              "      <td>1</td>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4.585</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84348301</th>\n",
              "      <td>1</td>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1.1560</td>\n",
              "      <td>3.445</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.01867</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.91</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84358402</th>\n",
              "      <td>1</td>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.1980</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5.438</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.01885</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.54</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          diagnosis  radius_mean  ...  symmetry_worst  fractal_dimension_worst\n",
              "id                                ...                                         \n",
              "842302            1        17.99  ...          0.4601                  0.11890\n",
              "842517            1        20.57  ...          0.2750                  0.08902\n",
              "84300903          1        19.69  ...          0.3613                  0.08758\n",
              "84348301          1        11.42  ...          0.6638                  0.17300\n",
              "84358402          1        20.29  ...          0.2364                  0.07678\n",
              "\n",
              "[5 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "olkN3PKIo26I"
      },
      "source": [
        "# Create training and test sets\n",
        "# Using a seed for the random number generator to ensure the split is the same every time\n",
        "# for the purposes of this project\n",
        "training_set, test_set = train_test_split(bcwd, test_size=0.20, random_state=42)\n",
        "\n",
        "# Use all of the features, excluding diagnosis at the beginning\n",
        "training_features = training_set.iloc[:,1:]\n",
        "# Targets are at the end\n",
        "training_targets = training_set.iloc[:,0]\n",
        "\n",
        "# Pull out the same features and targets from test set\n",
        "testing_features = test_set.iloc[:,1:]\n",
        "testing_targets = test_set.iloc[:,0]\n",
        "\n",
        "# Use this list of measurements to score your cross-validation results\n",
        "scoring = ['accuracy','precision', 'recall', 'f1']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YkI5Er2jDy26"
      },
      "source": [
        "# Part One\n",
        "\n",
        "In this part we will train a series of random forest models using cross-validation. We will perform what is called a grid search of two different hyperparameters. A grid search explores different combinations of values across multiple hyperparamters. \n",
        "\n",
        "For our purposes, we will explore max_features and max_depth. Max_features specifies how many features each tree has access too. Max_depth limits the growth of the tree. We will explore two values (small and large) for max_features, 4 and 20, and two values of max_depth, 4 and 10. This means a total of 4 models will be created. \n",
        "\n",
        "The first model with max_features=4 and max_depth=4 has code ready to go. You will need to create the other three models that have different pairings of hyperparameter values. Finally, pick your model with the highest test_accuracy and evaluate it on the test set (Code is given for this, but you must set the hyperparameters based on your results).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPTFXPon9DuC",
        "outputId": "9ee8939e-bb40-465d-bb9f-4d7a27719d73",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Sample code of a random forest cross-validation run\n",
        "\n",
        "# Create the random forest model with max_features=4 and max_depth=4\n",
        "rf_model = RandomForestClassifier(criterion='entropy', max_features=4, max_depth=4)\n",
        "\n",
        "# Cross validation calculating multiple metrics\n",
        "rf_model.fit(training_features, training_targets)\n",
        "scores = cross_validate(rf_model, training_features, training_targets, scoring=scoring, return_train_score=True, cv=5)\n",
        "\n",
        "# Average the runs\n",
        "results = pd.DataFrame(scores)\n",
        "results.mean()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "fit_time           0.174091\n",
              "score_time         0.010752\n",
              "test_accuracy      0.947253\n",
              "train_accuracy     0.991758\n",
              "test_precision     0.956665\n",
              "train_precision    1.000000\n",
              "test_recall        0.899465\n",
              "train_recall       0.977821\n",
              "test_f1            0.926379\n",
              "train_f1           0.988775\n",
              "dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RX5TMT2_lQa",
        "outputId": "c9a347a9-e1d2-4c44-de48-d94a166c4f22",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Create the random forest model with max_features=4 and max_depth=10\n",
        "rf_model2 = RandomForestClassifier(criterion='entropy', max_features=4, max_depth=10)\n",
        "\n",
        "# Cross validation calculating multiple metrics\n",
        "rf_model2.fit(training_features, training_targets)\n",
        "scores2 = cross_validate(rf_model2, training_features, training_targets, scoring=scoring, return_train_score=True, cv=5)\n",
        "\n",
        "# Average the runs\n",
        "results2 = pd.DataFrame(scores2)\n",
        "results2.mean()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "fit_time           0.176041\n",
              "score_time         0.010390\n",
              "test_accuracy      0.960440\n",
              "train_accuracy     1.000000\n",
              "test_precision     0.969521\n",
              "train_precision    1.000000\n",
              "test_recall        0.923173\n",
              "train_recall       1.000000\n",
              "test_f1            0.944860\n",
              "train_f1           1.000000\n",
              "dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3nn3HAY_ny-",
        "outputId": "985e55f9-e705-427c-fb0e-156e05ef6316",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Create the random forest model with max_features=20 and max_depth=4\n",
        "rf_model3 = RandomForestClassifier(criterion='entropy', max_features=20, max_depth=4)\n",
        "\n",
        "# Cross validation calculating multiple metrics\n",
        "rf_model3.fit(training_features, training_targets)\n",
        "scores3 = cross_validate(rf_model3, training_features, training_targets, scoring=scoring, return_train_score=True, cv=5)\n",
        "\n",
        "# Average the runs\n",
        "results3 = pd.DataFrame(scores3)\n",
        "results3.mean()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "fit_time           0.351327\n",
              "score_time         0.010493\n",
              "test_accuracy      0.956044\n",
              "train_accuracy     0.993956\n",
              "test_precision     0.958173\n",
              "train_precision    1.000000\n",
              "test_recall        0.922995\n",
              "train_recall       0.983736\n",
              "test_f1            0.939339\n",
              "train_f1           0.991799\n",
              "dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Z00oKRPBIpZ",
        "outputId": "a76285a3-443c-4e46-fad1-6be9eb54e455",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Create the random forest model with max_features=20 and max_depth=10\n",
        "rf_model4 = RandomForestClassifier(criterion='entropy', max_features=20, max_depth=10)\n",
        "                                   \n",
        "# Cross validation calculating multiple metrics\n",
        "rf_model4.fit(training_features, training_targets)\n",
        "scores4 = cross_validate(rf_model4, training_features, training_targets, scoring=scoring, return_train_score=True, cv=5)\n",
        "\n",
        "# Average the runs\n",
        "results4 = pd.DataFrame(scores4)\n",
        "results4.mean()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "fit_time           0.366364\n",
              "score_time         0.010591\n",
              "test_accuracy      0.960440\n",
              "train_accuracy     1.000000\n",
              "test_precision     0.952491\n",
              "train_precision    1.000000\n",
              "test_recall        0.940998\n",
              "train_recall       1.000000\n",
              "test_f1            0.946150\n",
              "train_f1           1.000000\n",
              "dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbzY8pq37VIZ",
        "outputId": "b1b8f234-715e-405c-d7f2-5c118f14c732",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Sample code evaluating an rf model on the test set\n",
        "# Customize it as appropriate\n",
        "rf_model5 = RandomForestClassifier(criterion='entropy', max_features=4, max_depth=10)\n",
        "rf_model5.fit(training_features, training_targets)\n",
        "\n",
        "rf_model5.score(testing_features, testing_targets)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9649122807017544"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Zh0CHcDGYfQ"
      },
      "source": [
        "## Questions on Part One\n",
        "\n",
        "1) Which model had the highest accuracy test_accuracy score?\n",
        "\n",
        "*The random forest models with `max_features = 4` and `max_depth=10` and `max_features = 20` and `max_depth=10` had the highest test_accuracy score of 0.960440.*\n",
        "\n",
        "2) Which model had the highest test_f1 score?\n",
        "\n",
        "*The random forest model with `max_features = 20` and `max_depth=10` had the highest test_f1 score of 0.946150.*\n",
        "\n",
        "3) Which model had the highest fit_time? Why do you think this is?\n",
        "\n",
        "*The random forest model with `max_features = 20` and `max_depth=10` has the highest fit_time of 0.366364. I think it is because the model has access to 20 features and it takes time to go through those 20 features. The model also has a max depth of 10 which means it takes time for the growth of the tree to a depth of 10.*\n",
        "\n",
        "4) Which model had the lowest fit_time? Why do you think this is?\n",
        "\n",
        "*The random forest model with `max_features = 4` and `max_depth=4` has the lowest fit_time of 0.183027. I think this it is because the model has the least number of maximum features to use and also the least number of maximum depths for the tree.*\n",
        "\n",
        "5) Does the model with the highest fit_time have the best f1 score?\n",
        "\n",
        "*Yes, the random forest model with `max_features = 20` and `max_depth=10` has both the highest fit_time and the best f1 score.*\n",
        "\n",
        "6) Did you see any evidence of over-fitting from the training accuracy scores?\n",
        "\n",
        "*No, I do not see any evidence of overfitting from the training accuracy scores as there is no vast difference between the train_accuracy and test_accuracy scores. They are just off by a few points. The test_accuracy scores are also not that relatively poor which would reflect that the model is not performing better on unseen instances.*\n",
        "\n",
        "7) How did your best model in terms of test_accuracy score do when evaluated on the testing set using the score method? How different were the results from the test_accuracy score during cross-validation? \n",
        "\n",
        "*The best model in terms of test_accuracy score did slightly better when evaluated on the testing set using the score method. The accuracy from the score method came out to be 0.96491 whereas the test_accuracy score during cross validation was 0.960440.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HtVWuxVw5Ihr"
      },
      "source": [
        "# Part Two\n",
        "In part two we will explore using k-nearest neighbors algorithm. First, we will investigate whether scaling the data improves results. Second, we will use cross-validation to set the k value of our model. \n",
        "\n",
        "Code is given to create and evaluate a k-nearest neighbors model with K=3 on the original data. Code is then given to scale the data. You need to then recreate the knn model with K=3 and evalute its performance on the scaled data. Then create knn models with K=7 and K=12 and evaluate them. Finally, pick your model with the highest test_accuracy and evaluate it on the test set (Code is given for this, but you must set the correct K value).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_Z1sKb_vSHd"
      },
      "source": [
        "training_set, test_set = train_test_split(bcwd, test_size=0.20, random_state=42)\n",
        "\n",
        "# Use all of the features, excluding diagnosis at the beginning\n",
        "training_features = training_set.iloc[:,1:]\n",
        "# Targets are at the end\n",
        "training_targets = training_set.iloc[:,0]\n",
        "\n",
        "# Pull out the same features and targets from test set\n",
        "testing_features = test_set.iloc[:,1:]\n",
        "testing_targets = test_set.iloc[:,0]\n",
        "\n",
        "# Use this list of measurements to score your cross-validation results\n",
        "scoring = ['accuracy','precision', 'recall', 'f1']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ShMzVn2h3LiI",
        "outputId": "6c0ff6b3-940e-4f23-8aba-85e3c58b2355",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Create KNN model with n_neighbors=3, train on original data\n",
        "knn_model = KNeighborsClassifier(n_neighbors=3)\n",
        "\n",
        "# Cross validation calculating multiple metrics\n",
        "knn_model.fit(training_features, training_targets)\n",
        "scores = cross_validate(knn_model, training_features, training_targets, scoring=scoring, return_train_score=True, cv=5)\n",
        "\n",
        "# Average the runs\n",
        "results = pd.DataFrame(scores)\n",
        "results.mean()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "fit_time           0.002778\n",
              "score_time         0.007360\n",
              "test_accuracy      0.920879\n",
              "train_accuracy     0.948901\n",
              "test_precision     0.934580\n",
              "train_precision    0.964923\n",
              "test_recall        0.846702\n",
              "train_recall       0.895000\n",
              "test_f1            0.886192\n",
              "train_f1           0.928605\n",
              "dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgkG-JAs79r1"
      },
      "source": [
        "# Scale the features to have a mean of 0 and a standard deviation of 1\n",
        "feature_scaler = StandardScaler().fit(training_features)\n",
        "training_features_scaled = feature_scaler.transform(training_features)\n",
        "testing_features_scaled = feature_scaler.transform(testing_features)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qt8vLe58FKf",
        "outputId": "cfbd0c60-d9ab-4662-9b98-665198e847df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Create KNN model with n_neighbors=3, train on scaled data\n",
        "knn_model_sc = KNeighborsClassifier(n_neighbors=3)\n",
        "\n",
        "# Cross validation calculating multiple metrics\n",
        "knn_model_sc.fit(training_features_scaled, training_targets)\n",
        "scores_sc = cross_validate(knn_model_sc, training_features_scaled, training_targets, scoring=scoring, return_train_score=True, cv=5)\n",
        "\n",
        "# Average the runs\n",
        "results_sc = pd.DataFrame(scores_sc)\n",
        "results_sc.mean() "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "fit_time           0.001431\n",
              "score_time         0.008014\n",
              "test_accuracy      0.960440\n",
              "train_accuracy     0.982418\n",
              "test_precision     0.974531\n",
              "train_precision    0.996947\n",
              "test_recall        0.917291\n",
              "train_recall       0.955621\n",
              "test_f1            0.944211\n",
              "train_f1           0.975814\n",
              "dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xm3IKheD_l8z",
        "outputId": "ee4a3bf8-35dd-4dfd-9c06-381246192028",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Create KNN model with n_neighbors=7, train on scaled data\n",
        "knn_model2_sc = KNeighborsClassifier(n_neighbors=7)\n",
        "\n",
        "# Cross validation calculating multiple metrics\n",
        "knn_model2_sc.fit(training_features_scaled, training_targets)\n",
        "scores2_sc = cross_validate(knn_model2_sc, training_features_scaled, training_targets, scoring=scoring, return_train_score=True, cv=5)\n",
        "\n",
        "# Average the runs\n",
        "results2_sc = pd.DataFrame(scores2_sc)\n",
        "results2_sc.mean() "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "fit_time           0.001331\n",
              "score_time         0.007638\n",
              "test_accuracy      0.960440\n",
              "train_accuracy     0.971429\n",
              "test_precision     0.981339\n",
              "train_precision    0.998374\n",
              "test_recall        0.911586\n",
              "train_recall       0.924575\n",
              "test_f1            0.943823\n",
              "train_f1           0.959980\n",
              "dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9HJxpoc_nt9",
        "outputId": "ac083bd3-a327-415f-a7b7-41bd21405a96",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Create KNN model with n_neighbors=12, train on scaled data\n",
        "knn_model3_sc = KNeighborsClassifier(n_neighbors=12)\n",
        "\n",
        "# Cross validation calculating multiple metrics\n",
        "knn_model3_sc.fit(training_features_scaled, training_targets)\n",
        "scores3_sc = cross_validate(knn_model3_sc, training_features_scaled, training_targets, scoring=scoring, return_train_score=True, cv=5)\n",
        "\n",
        "# Average the runs\n",
        "results3_sc = pd.DataFrame(scores3_sc)\n",
        "results3_sc.mean() "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "fit_time           0.001443\n",
              "score_time         0.008831\n",
              "test_accuracy      0.953846\n",
              "train_accuracy     0.963187\n",
              "test_precision     0.993548\n",
              "train_precision    0.998319\n",
              "test_recall        0.881818\n",
              "train_recall       0.902364\n",
              "test_f1            0.933414\n",
              "train_f1           0.947875\n",
              "dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blcj4iD2_rPk",
        "outputId": "4e79b7fb-72ad-4ea6-d2a5-fe6d1086058f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Sample code evaluating a knn model on the scaled test set\n",
        "# Customize it as appropriate\n",
        "knn_model = KNeighborsClassifier(n_neighbors=3)\n",
        "knn_model.fit(training_features_scaled, training_targets)\n",
        "\n",
        "# The score method is quick way of getting the accuracy on the testing data\n",
        "knn_model.score(testing_features_scaled, testing_targets)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9473684210526315"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S17MEXtH_4vv"
      },
      "source": [
        "## Questions for Part Two\n",
        "\n",
        "1) Did the results from KNN model change when you switched to scaled features?\n",
        "\n",
        "*Yes, the results from the KNN model change when I switched to scaled features. All the scores of the model with scaled features improved than those for the model without scaled features.* \n",
        "\n",
        "2) Which KNN model had the highest test_accuracy? Did it also have the highest test_f1 score? Is precision or recall higher and what does that say about the model's performance?\n",
        "\n",
        "*Two models with scaled features, each with n_neighbors = 3 and n_neighbors = 7 had the highest test_accuracy of 0.960440. The scaled model with n_neighbors = 3 had the highest test_f1 score of 0.944211.*\n",
        "\n",
        "*For the model with n_neighbors = 3, both the test_precision and train_precision are higher than test_recall and train_recall. This tells us that the precentage of total relevant results correctly classified by the model is lower than the actual percentage of relevant results in the model.*\n",
        "\n",
        "3) How did your best model in terms of test_accuracy do when evaluated on the testing set? Did the accuracy go up or down and by how much?\n",
        "\n",
        "*My best model in terms of test_accuracy did fine when evaluated on the testing set. The accuracy went slightly down by 1.3072% (from 96.0440% to 94.7368%).*\n",
        "\n",
        "4) How does your best KNN model compare to your best Random Forest model in terms of accuracy on the testing set?\n",
        "\n",
        "*My best Random Forest model did better than my best KNN model in terms of accuracy on the testing set. The accuracy on the testing set from the best random forest model was 96.491% (slightly higher than the test_accuracy score during cross validation which was 96.0440%) whereas the accuracy on the testing set model from the best KNN model was 94.7368% (lower that the test_accuracy, 96.0440%).*\n",
        "\n",
        "5) How do fit_times compare between the KNN models and the Random Forest models?\n",
        "\n",
        "*The fit_times for the KNN models are much lower than the fit_times for the Random Forest models. This might be because the random forest model has to build a tree in order to reach to the features with the best information gain in order to make its predictions.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AxIhMndlt0E5"
      },
      "source": [
        "*THANK YOU*"
      ]
    }
  ]
}